# LLM上下文工程重构设计文档

## 1. 背景与问题

### 1.1 当前问题
在当前系统中，处理持续对话（如脚本修改）时存在以下问题：
- 将之前的生成内容作为assistant角色的最后一条消息，导致LLM无法正常返回新内容
- 违反了LLM期望的user/assistant角色交替原则
- 缺乏统一的上下文管理机制，不同工具实现方式不一致
- 长对话场景下token使用效率低，成本高

### 1.2 具体案例
```java
// 当前错误的实现方式
messages = [
    {"role": "system", "content": "播客脚本生成专家..."},
    {"role": "user", "content": "介绍港乐"},
    {"role": "assistant", "content": "没问题，我会为你生成..."},
    {"role": "user", "content": "脚本内容修改为幽默风格"},
    {"role": "assistant", "content": "这是上次生成的脚本：[完整脚本内容]"}  // 错误：assistant作为最后消息
]
```

## 2. 解决方案：元数据分离法

### 2.1 核心理念
通过结构化的用户消息传递所有上下文信息，确保对话始终以user角色结束。

### 2.2 实现方式
```java
// 正确的实现方式
messages = [
    {"role": "system", "content": "播客脚本生成专家..."},
    {"role": "user", "content": """
<context>
原始需求：介绍港乐
意图识别：用户想要了解香港流行音乐的发展历史
之前版本：
[之前生成的脚本内容]
</context>

<instruction>
请将脚本修改为幽默风格
</instruction>
"""}
]
```

## 3. 详细设计

### 3.1 核心数据结构

```java
/**
 * 对话上下文元数据
 */
@Data
@Builder
public class ChatMetadata {
    /**
     * 原始用户请求
     */
    private String originalRequest;
    
    /**
     * 意图识别结果
     */
    private String intentRecognition;
    
    /**
     * 之前的生成内容
     */
    private String previousGeneration;
    
    /**
     * 搜索结果或参考资料
     */
    private String searchResults;
    
    /**
     * 其他上下文信息
     */
    private Map<String, String> additionalContext;
    
    /**
     * 对话历史摘要（用于长对话）
     */
    private String chatSummary;
}
```

### 3.2 消息构建器

```java
/**
 * 统一的消息构建器
 */
@Component
public class LLMMessageBuilder {
    
    /**
     * 构建带元数据的用户消息
     */
    public Message buildUserMessageWithMetadata(ChatMetadata metadata, String instruction) {
        StringBuilder content = new StringBuilder();
        
        // 构建上下文部分
        if (metadata != null) {
            content.append("<context>\n");
            
            // 优先级1：意图识别结果
            if (StringUtils.isNotBlank(metadata.getIntentRecognition())) {
                content.append("意图识别结果：\n");
                content.append(metadata.getIntentRecognition()).append("\n\n");
            }
            
            // 优先级2：原始需求
            if (StringUtils.isNotBlank(metadata.getOriginalRequest())) {
                content.append("原始需求：").append(metadata.getOriginalRequest()).append("\n\n");
            }
            
            // 优先级3：搜索结果
            if (StringUtils.isNotBlank(metadata.getSearchResults())) {
                content.append("参考资料：\n");
                content.append(metadata.getSearchResults()).append("\n\n");
            }
            
            // 优先级4：之前的生成内容
            if (StringUtils.isNotBlank(metadata.getPreviousGeneration())) {
                content.append("之前版本：\n");
                content.append(metadata.getPreviousGeneration()).append("\n\n");
            }
            
            // 优先级5：对话摘要
            if (StringUtils.isNotBlank(metadata.getChatSummary())) {
                content.append("对话历史摘要：\n");
                content.append(metadata.getChatSummary()).append("\n\n");
            }
            
            // 其他上下文信息
            if (metadata.getAdditionalContext() != null && !metadata.getAdditionalContext().isEmpty()) {
                metadata.getAdditionalContext().forEach((key, value) -> {
                    content.append(key).append("：").append(value).append("\n");
                });
                content.append("\n");
            }
            
            content.append("</context>\n\n");
        }
        
        // 构建指令部分
        content.append("<instruction>\n");
        content.append(instruction);
        content.append("\n</instruction>");
        
        return Message.builder()
            .role("user")
            .content(content.toString())
            .build();
    }
}
```

### 3.3 工具执行服务重构

```java
@Service
@Slf4j
public class ToolExecutionService {
    
    @Autowired
    private LLMMessageBuilder messageBuilder;
    
    @Autowired
    private LLMService llmService;
    
    /**
     * 执行工具（使用元数据方式）
     */
    public ExecutionResult executeToolWithMetadata(
            String toolName, 
            ChatMetadata metadata,
            String instruction,
            ToolExecutionContext context) {
        
        try {
            // 1. 获取工具配置
            ToolConfig config = getToolConfig(toolName);
            
            // 2. 构建消息列表
            List<Message> messages = new ArrayList<>();
            
            // 添加系统提示
            messages.add(Message.builder()
                .role("system")
                .content(config.getSystemPrompt())
                .build());
            
            // 添加带元数据的用户消息
            Message userMessage = messageBuilder.buildUserMessageWithMetadata(metadata, instruction);
            messages.add(userMessage);
            
            // 3. 调用LLM
            LLMResponse response = llmService.chat(messages, context.getModel());
            
            // 4. 处理响应
            return ExecutionResult.builder()
                .success(true)
                .result(response.getContent())
                .toolName(toolName)
                .build();
                
        } catch (Exception e) {
            log.error("工具执行失败 - toolName: {}, error: {}", toolName, e.getMessage(), e);
            return ExecutionResult.builder()
                .success(false)
                .error(e.getMessage())
                .build();
        }
    }
}
```

### 3.4 播客脚本服务重构示例

```java
@Service
@Slf4j
public class PodcastScriptService {
    
    @Autowired
    private ToolExecutionService toolExecutionService;
    
    /**
     * 修改播客脚本
     */
    public String modifyScript(
            String dialogId, 
            String previousScript, 
            String modificationRequest,
            String intentRecognition) {
        
        // 1. 构建元数据
        ChatMetadata metadata = ChatMetadata.builder()
            .intentRecognition(intentRecognition)
            .previousGeneration(previousScript)
            .additionalContext(Map.of(
                "对话ID", dialogId,
                "修改时间", LocalDateTime.now().toString()
            ))
            .build();
        
        // 2. 执行工具
        ExecutionResult result = toolExecutionService.executeToolWithMetadata(
            "radio_script_modify",
            metadata,
            modificationRequest,
            ToolExecutionContext.builder()
                .dialogId(dialogId)
                .build()
        );
        
        // 3. 返回结果
        if (result.isSuccess()) {
            return result.getResult();
        } else {
            throw new RuntimeException("脚本修改失败: " + result.getError());
        }
    }
}
```

## 4. 长对话管理策略

### 4.1 Token计数与阈值管理

```java
@Component
public class ChatContextManager {
    
    private static final int MAX_CONTEXT_TOKENS = 4000;
    private static final int SUMMARY_THRESHOLD = 3000;
    
    /**
     * 管理对话上下文，防止超过token限制
     */
    public ChatMetadata manageContext(String sessionId, ChatMetadata fullMetadata) {
        // 1. 计算当前token数量
        int currentTokens = calculateTokens(fullMetadata);
        
        // 2. 如果未超过阈值，直接返回
        if (currentTokens <= MAX_CONTEXT_TOKENS) {
            return fullMetadata;
        }
        
        // 3. 需要压缩
        log.info("对话上下文超过token限制，开始压缩 - sessionId: {}, currentTokens: {}", 
                sessionId, currentTokens);
        
        return compressContext(fullMetadata);
    }
    
    /**
     * 压缩上下文
     */
    private ChatMetadata compressContext(ChatMetadata original) {
        ChatMetadata compressed = ChatMetadata.builder()
            .originalRequest(original.getOriginalRequest())  // 保留原始请求
            .intentRecognition(original.getIntentRecognition())  // 保留意图识别
            .build();
        
        // 对历史内容进行摘要
        if (StringUtils.isNotBlank(original.getPreviousGeneration())) {
            String summary = summarizeContent(original.getPreviousGeneration());
            compressed.setChatSummary(summary);
        }
        
        // 只保留最重要的附加上下文
        Map<String, String> essentialContext = new HashMap<>();
        if (original.getAdditionalContext() != null) {
            // 筛选关键信息
            original.getAdditionalContext().forEach((key, value) -> {
                if (isEssentialContext(key)) {
                    essentialContext.put(key, value);
                }
            });
        }
        compressed.setAdditionalContext(essentialContext);
        
        return compressed;
    }
}
```

### 4.2 对话历史存储与检索

```java
@Service
public class ChatHistoryService {
    
    @Autowired
    private RedisTemplate<String, Object> redisTemplate;
    
    /**
     * 保存对话轮次
     */
    public void saveChatTurn(String sessionId, ChatMetadata metadata, String response) {
        String key = "chat:" + sessionId;
        
        ChatTurn turn = ChatTurn.builder()
            .timestamp(System.currentTimeMillis())
            .metadata(metadata)
            .response(response)
            .build();
        
        // 保存到Redis列表
        redisTemplate.opsForList().rightPush(key, turn);
        
        // 设置过期时间（24小时）
        redisTemplate.expire(key, 24, TimeUnit.HOURS);
    }
    
    /**
     * 获取最近N轮对话
     */
    public List<ChatTurn> getRecentTurns(String sessionId, int n) {
        String key = "chat:" + sessionId;
        List<Object> turns = redisTemplate.opsForList().range(key, -n, -1);
        
        return turns.stream()
            .map(obj -> (ChatTurn) obj)
            .collect(Collectors.toList());
    }
}
```

## 5. 实施计划

### 5.1 第一阶段：基础设施建设（2天）
- [ ] 创建ChatMetadata类
- [ ] 实现LLMMessageBuilder
- [ ] 创建ChatContextManager
- [ ] 单元测试

### 5.2 第二阶段：核心服务重构（4天）
- [ ] 重构ToolExecutionService
- [ ] 更新ChatContextDTO
- [ ] 迁移现有工具策略
- [ ] 集成测试

### 5.3 第三阶段：播客服务优化（3天）
- [ ] 重构播客脚本生成和修改功能
- [ ] 实现脚本版本管理
- [ ] 优化上下文传递链路
- [ ] 端到端测试

### 5.4 第四阶段：高级功能（2天）
- [ ] 实现对话压缩算法
- [ ] 添加向量检索支持
- [ ] 性能优化
- [ ] 监控和报警

## 6. 兼容性与迁移

### 6.1 向后兼容
```java
// 提供适配器模式，支持旧接口
@Component
public class LegacyToolAdapter {
    
    @Autowired
    private ToolExecutionService newService;
    
    public ExecutionResult executeToolOldWay(String toolName, Map<String, Object> params) {
        // 转换为新格式
        ChatMetadata metadata = convertParamsToMetadata(params);
        String instruction = extractInstruction(params);
        
        // 调用新接口
        return newService.executeToolWithMetadata(toolName, metadata, instruction, null);
    }
}
```

### 6.2 数据迁移
- 提供批量迁移工具
- 支持增量迁移
- 保留历史数据备份

## 7. 性能考虑

### 7.1 缓存策略
- 对话元数据缓存
- LLM响应缓存
- 摘要结果缓存

### 7.2 异步处理
- 对话压缩异步化
- 历史记录异步持久化
- 向量索引异步更新

## 8. 监控指标

- Token使用量统计
- 对话压缩比率
- 缓存命中率
- 平均响应时间
- 错误率统计

## 9. 风险评估与对策

### 9.1 技术风险
- **风险**：大规模重构可能引入新的bug
- **对策**：充分的测试覆盖，灰度发布

### 9.2 性能风险
- **风险**：额外的处理可能影响响应时间
- **对策**：缓存优化，异步处理

### 9.3 成本风险
- **风险**：结构化标签可能增加token使用
- **对策**：智能压缩，动态调整策略

## 10. 参考资料

1. [LLM Context Engineering Best Practices 2024](https://www.llamaindex.ai/blog/context-engineering-what-it-is-and-techniques-to-consider)
2. [Managing Context History for LLMs](https://verticalserve.medium.com/genai-managing-context-history-best-practices-a350e57cc25f)
3. [Chatal Memory Patterns](https://www.pinecone.io/learn/series/langchain/langchain-chatal-memory/)

## 11. 总结

通过元数据分离法重构，我们将实现：
1. 统一的上下文管理机制
2. 符合LLM最佳实践的消息结构
3. 高效的长对话支持
4. 更好的可维护性和扩展性

这个重构将为系统的长期发展奠定坚实基础。